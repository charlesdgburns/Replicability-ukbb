{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = '/data/sliu/sampling_ukbb_analysis/data/'\n",
    "t = 'Age'\n",
    "data_path2 = os.path.join(data_path,t)\n",
    "CSA_file_name = 'CSA_with_controlling_for_total_brain.csv'\n",
    "CSA_file_path = os.path.join(data_path2,CSA_file_name)\n",
    "CT_file_name = 'CT_with_controlling_for_total_brain.csv'\n",
    "CT_file_path = os.path.join(data_path2,CT_file_name)\n",
    "FC_file_name = 'FC_data.csv'\n",
    "FC_file_path = os.path.join(data_path2,FC_file_name)\n",
    "variable_name = 'variable_with_controlling_for_total_brain.csv'\n",
    "variable_file_path = os.path.join(data_path2,variable_name)\n",
    "\n",
    "CSA_data = pd.read_csv(CSA_file_path).iloc[:,:-1].values\n",
    "CT_data = pd.read_csv(CT_file_path).iloc[:,:-1].values\n",
    "FC_data = pd.read_csv(FC_file_path).iloc[:,:-1].values\n",
    "variable = pd.read_csv(variable_file_path).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_importances(imaging_data,variable):\n",
    "    s1 = imaging_data.shape\n",
    "    max_samples_num = int(s1[0]/200)\n",
    "    random_samples = []\n",
    "\n",
    "    for i in range(max_samples_num):\n",
    "        if i < 10:\n",
    "            random_samples.append(int(100*(i+1)))\n",
    "        else:\n",
    "            tmp = 1000 + 1000*(i-9)\n",
    "            if tmp < s1[0]/2:\n",
    "                random_samples.append(tmp)\n",
    "            else:\n",
    "                random_samples.append(int(s1[0]/2))\n",
    "                break\n",
    "#     random_samples = random_samples[:-4] %birth month\n",
    "    subsampling_times = len(random_samples)\n",
    "    random_num = 50\n",
    "    stability = np.zeros((subsampling_times,random_num,s1[1],2))\n",
    "    \n",
    "    for i in range(subsampling_times):\n",
    "        random_sample = random_samples[i]\n",
    "        print(random_sample)\n",
    "        for j in range(random_num):\n",
    "            total_list = np.arange(s1[0]).tolist()\n",
    "            random_inds1 = random.sample(total_list,random_sample)\n",
    "            rest_total_list = list(set(total_list) - set(random_inds1))\n",
    "            random_inds2 = random.sample(rest_total_list,random_sample)\n",
    "\n",
    "            Y1 = imaging_data[random_inds1,:]\n",
    "            Y2 = imaging_data[random_inds2,:]\n",
    "\n",
    "            m1 = variable[random_inds1]\n",
    "            m2 = variable[random_inds2]\n",
    "\n",
    "            reg1 = RandomForestRegressor(n_estimators=20)\n",
    "            reg2 = RandomForestRegressor(n_estimators=20)\n",
    "            reg1 = reg1.fit(Y1,m1)\n",
    "            reg2 = reg2.fit(Y2,m2)\n",
    "            stability[i,j,:,0] = reg1.feature_importances_\n",
    "            stability[i,j,:,1] = reg2.feature_importances_\n",
    "    \n",
    "    return stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating feature importance and saving\n",
    "CT_selection_stability = compute_feature_importances(CT_data,variable)\n",
    "CSA_selection_stability = compute_feature_importances(CSA_data,variable)\n",
    "FC_selection_stability = compute_feature_importances(FC_data,variable)\n",
    "\n",
    "CSA_file_name = 'stable_slection/'+t+'/feature_importances_CSA.npy'\n",
    "CT_file_name = 'stable_slection/'+t+'/feature_importances_CT.npy'\n",
    "FC_file_name = 'stable_slection/'+t+'/feature_importances_FC.npy'\n",
    "\n",
    "np.save(CSA_file_name,CSA_selection_stability)\n",
    "np.save(CT_file_name,CT_selection_stability)\n",
    "np.save(FC_file_name,FC_selection_stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Jaccard index\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def Jaccard_index(data,t=None):\n",
    "    s = data.shape\n",
    "    odata1 = np.zeros((s[0],2))\n",
    "    num_feature = int(t*s[2])\n",
    "    for i in range(s[0]):\n",
    "        tmp_l = []\n",
    "        for j in range(s[1]):\n",
    "            importances1 = data[i,j,:,0]\n",
    "            importances2 = data[i,j,:,1]\n",
    "            l1 = np.argsort(-importances1)[:num_feature]\n",
    "            l2 = np.argsort(-importances2)[:num_feature]\n",
    "            \n",
    "            seqs = np.zeros((s[2],2))\n",
    "            seqs[l1,0] = 1\n",
    "            seqs[l2,1] = 1\n",
    "            confusion_matrix1 = confusion_matrix(seqs[:,0],seqs[:,1])\n",
    "            confusion_matrix2 = np.zeros((2,2))\n",
    "            confusion_matrix2[0,0] = ((2*confusion_matrix1[0,0] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)**2\n",
    "            confusion_matrix2[1,1] = ((2*confusion_matrix1[1,1] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)**2\n",
    "            confusion_matrix2[0,1] = ((2*confusion_matrix1[0,0] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)\\\n",
    "            *((2*confusion_matrix1[1,1] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)\n",
    "            confusion_matrix2[1,0] = ((2*confusion_matrix1[0,0] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)\\\n",
    "            *((2*confusion_matrix1[1,1] + confusion_matrix1[0,1] + confusion_matrix1[1,0])/2)\n",
    "            \n",
    "            S = confusion_matrix1[1,1]/(confusion_matrix1[1,1] + confusion_matrix1[1,0] + confusion_matrix1[0,1])\n",
    "            ES = confusion_matrix2[1,1]/(confusion_matrix2[1,1] + confusion_matrix2[1,0] + confusion_matrix2[0,1])\n",
    "            \n",
    "            dd = (S - ES)/(1-ES)\n",
    "            tmp_l.append(dd)\n",
    "            \n",
    "        odata1[i,0] = np.mean(tmp_l)\n",
    "        odata1[i,1] = np.std(tmp_l)\n",
    "    return odata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Jaccard index\n",
    "files = ['Age', 'BMI','IQ','Numeric_memory', 'Neuroticism', 'Alcohol','Birth']\n",
    "# How many important features are included?:5%, 10%, 15%, 20%, 25%\n",
    "ts = [0.05,0.1,0.15,0.2,0.25]\n",
    "orders = [1,2,3,4,5]\n",
    "\n",
    "types = ['CSA','CT','FC']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#8c564b', '#9467bd', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "for k in range(5):\n",
    "    my_order = orders[k]\n",
    "    t = ts[k]\n",
    "    for j in range(len(types)):  \n",
    "        my_type = types[j]\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        for i in range(len(files)):\n",
    "            f = files[i]\n",
    "            \n",
    "            importance_file = 'stable_slection/'+f+'/feature_importances_'+my_type+'.npy'\n",
    "            importance_data = np.load(importance_file)\n",
    "            \n",
    "            reliability = Jaccard_index(importance_data,t)\n",
    "            \n",
    "            sample_sizes = pd.read_csv('stable_slection/'+f+'/'+my_type+'_selection_stability.csv').iloc[:,0].values\n",
    "\n",
    "            if f == 'Birth':\n",
    "                x = sample_sizes[:-4]\n",
    "            else:\n",
    "                x = sample_sizes\n",
    "            \n",
    "            y = reliability[:,0]\n",
    "\n",
    "            plt.plot(x,y,'k',color=colors[i],label=f,linewidth=4)\n",
    "#         if my_type == 'FC':\n",
    "#             plt.hlines(y=f_random_line,xmin=-500,xmax=15000,linestyles='dashed',linewidth=3,color ='black')\n",
    "#         else:\n",
    "#             plt.hlines(y=s_random_line,xmin=-500,xmax=15000,linestyles='dashed',linewidth=3,color ='black')\n",
    "        ax = plt.gca()\n",
    "        ax.spines['top'].set_linewidth(2)\n",
    "        ax.spines['bottom'].set_linewidth(2)\n",
    "        ax.spines['left'].set_linewidth(2)\n",
    "        ax.spines['right'].set_linewidth(2)\n",
    "        plt.ylabel('Jaccard index',fontsize=30)\n",
    "        plt.title(my_type+ \": top \" + str(int(100*t))+'% important features',fontsize=30)\n",
    "        plt.ylim(-0.05,1.1)\n",
    "        plt.xlim(-500,15000)\n",
    "        plt.xlabel('sample size',fontsize=30)\n",
    "        plt.tick_params(direction='out', length=10, width=4,labelsize=30)\n",
    "        output_file = 'stable_slection/correct_Jaccard_'+my_type+'_'+str(t)+'.png'\n",
    "        fig.savefig(output_file,dpi=300,bbox_inches = 'tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
